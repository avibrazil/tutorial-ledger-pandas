{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "korean-nation",
   "metadata": {},
   "source": [
    "# Handling Ledgers with Pandas, Python\n",
    "\n",
    "This notebook was also [published on my Medium column](https://avibrazil.medium.com/handling-monetary-ledgers-with-pandas-python-56c0a9509d48).\n",
    "\n",
    "A ledger is a table that records monetary trasactions, as credit or debit, and is always indexed in a chronological way, by date and time. It is used since ancient times to log account transactions and tell and reconstruct the history of events on that account.\n",
    "\n",
    "Ledger is a fundamental data management tool implemented in systems of banks and financial institutions. Before computer systems, banks already used ledgers as regular paper books to manage their clients accounts.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e6/Ledger.png\"/>\n",
    "\n",
    "Here is an example of a ledger recording transactions that happened on an account across 5 years. Positive transaction values are credits to that account, while negative values are debits or withdrawals.\n",
    "\n",
    "| Date | Transaction Value  | Comment |\n",
    "| :--------- | -----: | :--- |\n",
    "| 2015-05-15 | 100    | Salary |\n",
    "| 2016-02-06 | 200    | Project income |\n",
    "| 2016-08-10 | -30    | Gift for Max |\n",
    "| 2017-10-14 | -50   | Fix car |\n",
    "| 2018-02-01 | 400    | Project income |\n",
    "| 2018-06-06 | -20    | Lunch with family |\n",
    "| 2018-08-09 | 200    | Project income |\n",
    "| 2018-11-02 | -300   | House mortgage |\n",
    "| 2019-03-22 | 200    | Salary |\n",
    "| 2019-05-18 | 1000    | Ambitious project income |\n",
    "| 2019-12-24 | -15    | Christmas gift for Clara |\n",
    "| 2020-02-10 | -700    | House final mortgage |\n",
    "| 2020-08-01 | 600    | Project income |\n",
    "| 2020-12-09 | 20    | Last part of project income |\n",
    "\n",
    "Let's use code to create our exemplary ledger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ledger=pd.DataFrame(\n",
    "    columns=['date'  ,  'value', 'comment'],\n",
    "    data=[\n",
    "        ('2015-05-15',   100   , 'Salary'),\n",
    "        ('2016-02-06',   200   , 'Project income'),\n",
    "        ('2016-08-10',   -30   , 'Gift for Max'),\n",
    "        ('2017-10-14',   -50   , 'Fix car'),\n",
    "        ('2018-02-01',   400   , 'Project income'),\n",
    "        ('2018-06-06',   -20   , 'Lunch with family'),\n",
    "        ('2018-08-09',   200   , 'Project income'),\n",
    "        ('2018-11-02',  -300   , 'House mortgage'),\n",
    "        ('2019-03-22',   200   , 'Salary'),\n",
    "        ('2019-05-18',  1000   , 'Ambitious project income'),\n",
    "        ('2019-12-24',   -15   , 'Christmas gift for Clara'),\n",
    "        ('2020-02-10',  -700   , 'House final mortgage'),\n",
    "        ('2020-08-01',   600   , 'Project income'),\n",
    "        ('2020-12-09',    20   , 'Last part of project income')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Convert the textual `date` column into true datetime\n",
    "ledger.date=pd.to_datetime(ledger.date)\n",
    "\n",
    "# Make it the index of our dataframe\n",
    "ledger.set_index('date', inplace=True)\n",
    "\n",
    "ledger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-citation",
   "metadata": {},
   "source": [
    "Although they might look like ones, ledgers are not what we use to call time series. A ledger holds a lot of semantics but we’ll have to convert it into a time series in order to make it useful in calulations and plots. The ledger seen as time series is a table with the total balance at that point in time. For that we'll use Panda's `cumsum()` function that computes the cumulative sum — also known as balance — at each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "ledger_as_timeseries=ledger[['value']].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-savage",
   "metadata": {},
   "source": [
    "Don't forget to put in chronological order before making calculations with `cumsum()`, otherwise we'll get completely meaningless data. Our example is already sorted, but just in case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance=ledger[['value']].sort_index().cumsum().rename(columns={'value': 'balance'})\n",
    "balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-senior",
   "metadata": {},
   "source": [
    "This table is now a genuine time series. It conveys the ups and down of the balance across those 5 years of account story. It says that after its inception in 2015, with a credit of 100, it received more values but had withdrawals too, had a big credit in credit in May 2019 and finished 2020 with a balance of 1605. Can we plot it? Let's try (even if we are not ready yet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-immigration",
   "metadata": {},
   "source": [
    "This plot is wrong. Balance in 2015 did not grow continuosly as the line shows. Ledger data shows that balance was actually flat on 100 for most of the year of 2015 and then abruptly went to 300 in 2016-02.\n",
    "\n",
    "This bias happens because our time series (and ledger) has no regular frequency. Data is disposed as events happened, in random dates, which are not in a daily or monthly basis. We have a ragged time series and we'll have to turn it into a regular one, at least to corretly plot it.\n",
    "\n",
    "Pandas has outstanding tools to handle time. One of those is [`resample()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html) and [`pandas.Resampler`](https://pandas.pydata.org/docs/reference/resampling.html) which has the ability to put a discrete time series in an abstract state where time is linear and automatically manipulate the discrate values and infer what would be their linear incarnation. Then we'll use the `asfreq()` method to convert them back into something useful for plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency='1d' # daily frequency, but could be `1m` for monthly, or `1y` for yearly, or `1w` or `3m`...\n",
    "balance.resample(frequency).asfreq()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-hobby",
   "metadata": {},
   "source": [
    "This result is now much bigger because it was resampled into a daily time series (`frequency='1d'`). The space in between was filled with useless `NaN`s because we didn't tell `resample()` how to infer the empty space. For a fixed frequency table with daily balance, sorted in ascending order, we need `pandas.Resampler`'s `pad()` or `ffill()`. Use `backfill()` if your table is sorted in descending order. These methods also already encapsulate what `asfreq()` does, so we won't need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency='1d'\n",
    "balance.resample(frequency).ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-subcommittee",
   "metadata": {},
   "source": [
    "A lot of duplicate data. But at least we are now ready to plot it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency='1d'\n",
    "balance.resample(frequency).ffill().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-passion",
   "metadata": {},
   "source": [
    "Much better! Because it is now correct.\n",
    "\n",
    "## Handling multiple events at the same date and time\n",
    "\n",
    "The methods above will fail if you have multiple events at the same date. In Pandas terminology, you can't do resampling if you have 2 or more rows with same index value. Let's add an event to our ledger on a day that already has an event, 2017-10-14, and see how to handle that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "ledger=ledger.append(\n",
    "    pd.DataFrame(\n",
    "        index=pd.DatetimeIndex(['2017-10-14']),\n",
    "        data={\n",
    "            'value': -20,\n",
    "            'comment': 'some transaction'\n",
    "        }\n",
    "    )\n",
    ").sort_index()\n",
    "\n",
    "ledger[pd.Timestamp('2016-08-10'):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-guidance",
   "metadata": {},
   "source": [
    "To have 2 events on \"2017-10-14\" technicaly means for Pandas’ `Resampler` class that they both happened at the same second, which is \"2017-10-14 00:00:00\". `Resampler` doesn't know the actual order they really happened. Turns out that for a balance sheet with resolution as high as 1 day, it doesn't matter. So we'll add some random number of seconds to each date in the index, just to make them unique. We'll use NumPy for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Let's work with a copy of our ledger and leave the original intact\n",
    "precise_ledger=ledger.copy()\n",
    "\n",
    "precise_ledger.index=pd.DatetimeIndex(\n",
    "    (\n",
    "        # start with the original index\n",
    "        precise_ledger.index\n",
    "        # shift by some hours to set times to the middle of the day\n",
    "        + pd.DateOffset(hours=2)\n",
    "    # convert index to number of nanoseconds since 1970-01-01T00:00:00   \n",
    "    ).astype(np.int64)\n",
    "    # add random nanoseconds to each timestamp\n",
    "    + np.random.randint(\n",
    "        low  = -3600*(10**9),\n",
    "        high =  3600*(10**9),\n",
    "        size =  len(precise_ledger.index)\n",
    "    )\n",
    ") # convert it back to a DatetimeIndex\n",
    "\n",
    "precise_ledger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-pharmacy",
   "metadata": {},
   "source": [
    "Now our `pandas.DatetimeIndex` has unique values while still keeping the semantics of the date transactions happened.\n",
    "\n",
    "Let me know if you have a better way of achieving this.\n",
    "\n",
    "Let’s plot, even if visually it will be very similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency='1d'\n",
    "\n",
    "(\n",
    "    precise_ledger[['value']]\n",
    "    .sort_index()\n",
    "    .cumsum()\n",
    "    .rename(columns={'value': 'balance'})\n",
    "    .resample(frequency)\n",
    "    .ffill()\n",
    "    .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-legend",
   "metadata": {},
   "source": [
    "Run intermediate parts of the above one-liner in your notebook to understand what is happening in between. A recap:\n",
    "\n",
    "* We start with only the value parts of our ledger, excluding textual comments\n",
    "* Sort the index to have meaningful results\n",
    "* Calculate cumulative sum — a.k.a. balance — in the sorted DataFrame to convert a ledger into a time series\n",
    "* Rename the \"value\" column to \"balance\" just to keep up with the correct meaning\n",
    "* Use `resample()` to convert the discrete time series into a more linear one, with resolution of 1 day\n",
    "* Fill dates with no data with the last known balance, a forward fill operation\n",
    "* Plot it\n",
    "\n",
    "## Put all this procedure inside a useful function\n",
    "\n",
    "Note that we are permanently modifying the ledger index so it will be in sync with the generated balance. This is a bad practice for real production code, but makes this article shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_from_ledger(ledger, column='value', frequency=None):\n",
    "    # Increase index presicion converting it from plain date to a random time in the middle of that date.\n",
    "    # This is a technique to avoid duplicate index points while keeping the meaning of the transaction happened at that day.\n",
    "    # We need this to make resampling work as expected.\n",
    "    ledger.index=pd.DatetimeIndex(\n",
    "        (\n",
    "            ledger.index +                 # - the original index\n",
    "            pd.DateOffset(hours=2)         # - shift by 2 hours to set times to the middle of the day\n",
    "        ).astype(np.int64) +               # - convert them to number of nanoseconds since 1970-01-01T00:00:00\n",
    "        np.random.randint(                 # - add random nanoseconds to each timestamp\n",
    "            low  = -3600*(10**9),\n",
    "            high =  3600*(10**9),\n",
    "            size =  len(ledger.index)\n",
    "        )\n",
    "    )                                      # - convert it back to a DatetimeIndex\n",
    "    \n",
    "    # Make sure it is sorted\n",
    "    ledger.sort_index(inplace=True)\n",
    "\n",
    "    # Convert the list of transactions into a timeseries of the cumulative balance\n",
    "    balance=(\n",
    "        ledger[[column]]\n",
    "        .cumsum()\n",
    "        .rename(columns={column: 'balance'})\n",
    "    )\n",
    "    \n",
    "    if frequency:\n",
    "        return balance.resample(frequency).ffill()\n",
    "    else:\n",
    "        return balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-stewart",
   "metadata": {},
   "source": [
    "## Put transactions and balance side by side\n",
    "\n",
    "This can be achieved with a simple join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance=balance_from_ledger(ledger,'value')\n",
    "ledger.join(balance)[['value','balance','comment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-tunisia",
   "metadata": {},
   "source": [
    "## Compute balance yearly growth rate\n",
    "\n",
    "Investment applications are interested into growth rate which is a number that must be looked as a percentage and explains how much a monetary value growed or shrinked between 2 dates. It is defined by the simple formula $$growth_{d} = \\frac{balance_{d}}{balance_{d-1}}-1$$ having $d$ as the current period.\n",
    "\n",
    "So you can calculate balance of this period having the previous period and the growth rate:\n",
    "$$balance_{d}=balance_{d-1}(growth_{d}+1)$$\n",
    "\n",
    "First lets get a yearly perspective of balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_balance=balance_from_ledger(ledger,column='value',frequency='1y')\n",
    "yearly_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-diagnosis",
   "metadata": {},
   "source": [
    "This technique consists of putting current and previous balance in the same row and then do a simple math operation on that row. We'll use Panda's `shift()` and `join()` for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_balance.shift(1, fill_value=0).rename(columns={'balance': 'previous_balance'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-discussion",
   "metadata": {},
   "source": [
    "Join current and previous side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    yearly_balance\n",
    "    .join(\n",
    "        yearly_balance\n",
    "        .shift(1, fill_value=0)\n",
    "        .rename(columns={'balance': 'previous_balance'})\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-suggestion",
   "metadata": {},
   "source": [
    "All together in one shot with a fluent interface calculating growth rate and puting it side by side with the balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_balance.join(\n",
    "    \n",
    "    # Create a table that has current and previous balance on each year\n",
    "    \n",
    "    yearly_balance\n",
    "    .shift(1, fill_value=0)\n",
    "    .rename(columns={'balance': 'previous_balance'})\n",
    "    \n",
    ").apply(\n",
    "    # Our growth formula goes here:\n",
    "    \n",
    "    func=lambda year: year['balance']/year['previous_balance']-1,\n",
    "    axis=1\n",
    "    \n",
    ").rename('balance_growth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-wednesday",
   "metadata": {},
   "source": [
    "We read this like:\n",
    "* Balance on year end 2016 (270) increased 170% from year end 2015 (100)\n",
    "* Balance of year end 2017 (200) has shrinked 26% when compared to previous year (270)\n",
    "* And so on\n",
    "\n",
    "To compute monthly or weekly (or any other period) growth rate you just start with a different resampling. Lets do it in one block for a weekly view. The original output will have most of its `balance_growth==0` because balance doesn't change too frequently in this 5-year dataset, so we'll filter to show only the weeks that actually have growth using `query('balance_growth != 0')`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_balance=balance_from_ledger(\n",
    "    ledger,\n",
    "    column='value',\n",
    "    frequency='1w'\n",
    ")\n",
    "\n",
    "weekly_balance.join(\n",
    "    weekly_balance.join(\n",
    "        weekly_balance\n",
    "        .shift(1, fill_value=0)\n",
    "        .rename(columns={'balance': 'previous_balance'})\n",
    "    ).apply(\n",
    "        axis=1, \n",
    "        func=lambda week: week['balance']/week['previous_balance']-1\n",
    "    ).rename('balance_growth')\n",
    ").query('balance_growth != 0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
